{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'preprocess/')\n",
    "import vectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pickle.load(open('preprocess/sim_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.Attn_Sim_Pert as AttnModel\n",
    "Model = AttnModel.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = vec.vocab_size\n",
    "embed_size = vec.word_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xt = vec.seq_text['train'], vec.seq_text['test']\n",
    "y, yt = vec.label['train'], vec.label['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 = [i for i, x in enumerate(X) if len(x) <= 2]\n",
    "X = [x for i, x in enumerate(X) if i not in ind_1]\n",
    "y = [x for i, x in enumerate(y) if i not in ind_1]\n",
    "print(len(ind_1))\n",
    "ind_1 = [i for i, x in enumerate(Xt) if len(x) <= 2]\n",
    "Xt = [x for i, x in enumerate(Xt) if i not in ind_1]\n",
    "yt = [x for i, x in enumerate(yt) if i not in ind_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name='') :\n",
    "    model = Model(vocab_size, embed_size, 32, dirname='sim', hidden_size=6)\n",
    "    for i in tqdm_notebook(range(20)) :\n",
    "        loss = model.train(X, y)\n",
    "        print(loss)\n",
    "        o, he = model.evaluate(Xt)\n",
    "        o = np.array(o)\n",
    "        rep = classification_report(yt, (o > 0.5))\n",
    "        print(rep)\n",
    "        stmt = '%s, %s' % (i, loss)\n",
    "        dirname = model.save_values(add_name=name)\n",
    "        f = open(dirname + '/epoch.txt', 'a')\n",
    "        f.write(stmt + '\\n')\n",
    "        f.write(rep + '\\n')\n",
    "        f.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "shutil.rmtree('outputs/attn_sim_pert_sim', ignore_errors=True)\n",
    "for i in range(20) :\n",
    "    model = train(name='experiments_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dirname) :\n",
    "    model = Model(vocab_size, embed_size, 32, dirname='sst', hidden_size=6)\n",
    "    model.dirname = dirname\n",
    "    model.load_values(dirname)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exps = os.listdir('outputs/attn_sim_pert_sim/')\n",
    "exps = [e for e in exps if 'experiments' in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal_list = {}\n",
    "from sklearn.metrics import accuracy_score\n",
    "for e in exps :\n",
    "    dirname_normal = 'outputs/attn_sim_pert_sim/'+ e\n",
    "    model = load_model(dirname_normal)\n",
    "    o, he = model.evaluate(Xt)\n",
    "    o = np.array(o)\n",
    "    rep = accuracy_score(yt, (o > 0.5))\n",
    "    print(rep)\n",
    "    if rep > 0.7 :\n",
    "        model_normal_list[e] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = list(model_normal_list.keys())\n",
    "exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Xt\n",
    "ytest = yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_grads(model) :\n",
    "    predict_y, attn_test, perts_predict, perts_attn = model.evaluate(Xtest, sample=True)\n",
    "        \n",
    "    model.attn = attn_test\n",
    "    model.perts_predict = perts_predict\n",
    "    model.perts_attn = perts_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in model_normal_list.items() :\n",
    "    save_grads(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in model_normal_list :\n",
    "    attn = np.abs(np.array(model_normal_list[e].perts_attn))\n",
    "    actual = attn[np.eye(15)[np.array(Xtest)].astype('bool')].reshape((100, 10, 10))\n",
    "    m = attn.mean(2)\n",
    "    s = attn.std(2)\n",
    "\n",
    "    plt.hist(np.abs((actual - m)/s)[:, np.arange(7), np.arange(7)].flatten(), bins=30, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in model_normal_list :\n",
    "    attn = np.abs(np.array(model_normal_list[e].perts_attn))\n",
    "    attn1 = attn[:, np.arange(10), :, np.arange(10)]\n",
    "    med = np.median(attn1, 2)\n",
    "    sns.kdeplot(med.flatten(), cumulative=True)\n",
    "    idx = np.where((med > 0.5).any(axis=0))[0]\n",
    "    attn = np.abs(np.array(model_normal_list[e].perts_attn))\n",
    "    actual = attn[np.eye(15)[np.array(Xtest)].astype('bool')].reshape((100, 10, 10))\n",
    "    \n",
    "    for i in idx[:5] :\n",
    "        plt.matshow(np.vstack([np.diagonal(attn[i], 0, 0, 2), actual[i, 0:1, :]]).T, cmap='PuRd', vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in model_normal_list :\n",
    "    attn = np.abs(np.array(model_normal_list[e].perts_attn))\n",
    "    actual = attn[np.eye(15)[np.array(Xtest)].astype('bool')].reshape((100, 10, 10))\n",
    "    plt.matshow(np.vstack([np.diagonal(attn[0], 0, 0, 2), actual[0, 0:1, :]]), cmap='PuRd', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = np.abs(np.array(model_normal_list[exps[1]].perts_attn))\n",
    "attn = np.diagonal(attn, 0, 1, 3)\n",
    "plt.hist(attn.std(1).flatten(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
