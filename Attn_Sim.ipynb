{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <style>\n",
    "    .jp-Stdin-input {\n",
    "        width: 80% !important;\n",
    "        height : 1.5em !important;\n",
    "        font-size : 1em;\n",
    "        background : white;\n",
    "        border:1px solid #cccccc;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.set_printoptions(suppress=True)\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'preprocess/')\n",
    "import vectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pickle.load(open('preprocess/sim_data.p', 'rb'))\n",
    "add_frequencies(vec, vec.seq_text['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.Attn_Word_Pert as M\n",
    "Model = M.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xt = vec.seq_text['train'], vec.seq_text['test']\n",
    "y, yt = vec.label['train'], vec.label['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "def train(name='') :\n",
    "    model = Model(vec.vocab_size, vec.word_dim, 64, dirname='sim', hidden_size=6)\n",
    "    best_f1 = 0.0\n",
    "    for i in tqdm_notebook(range(30)) :\n",
    "        loss = model.train(X, y)\n",
    "        o, he = model.evaluate(Xt)\n",
    "        o = np.array(o)\n",
    "        rep = classification_report(yt, (o > 0.5))\n",
    "        f1 = f1_score(yt, (o > 0.5), pos_label=1)\n",
    "        print(rep)\n",
    "        stmt = '%s, %s' % (i, loss)\n",
    "        if True : #f1 > best_f1 :\n",
    "            best_f1 = f1\n",
    "            dirname = model.save_values(add_name=name, save_model=True)\n",
    "            print(\"Model Saved\", f1)\n",
    "        else :\n",
    "            dirname = model.save_values(add_name=name, save_model=False)\n",
    "            print(\"Model not saved\", f1)\n",
    "        f = open(dirname + '/epoch.txt', 'a')\n",
    "        f.write(stmt + '\\n')\n",
    "        f.write(rep + '\\n')\n",
    "        f.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20) :\n",
    "    train(name='TEST_sim_exp_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dirs = os.listdir('outputs/attn_word_sim/')\n",
    "dirs = [d for d in dirs if 'exp' in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in dirs :\n",
    "    model = load_model('outputs/attn_word_sim/' + e)\n",
    "    yt_hat, attn_hat = evaluate_and_print(model, Xt, yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dirname) :\n",
    "    model = Model(vec.vocab_size, vec.word_dim, 32, dirname='sst', hidden_size=6)\n",
    "    model.dirname = dirname\n",
    "    model.load_values(dirname)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('outputs/attn_word_sim/FriOct1913:14:512018_TEST_sim_exp_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_hat, attn_hat = evaluate_and_print(model, Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_entropy(Xt, attn_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "print_attn(vec.map2words(Xt[n]), attn_hat[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Sampling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vec = vec\n",
    "sampled_output = model.sampling_top(Xt, sample_vocab=100, topnum=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sampled_output, open(model.dirname + '/sampled.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_output = pickle.load(open(model.dirname + '/sampled.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_medians_from_sampling_top(sampled_output, attn_hat, yt_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractors = get_distractors(sampled_output, attn_hat)\n",
    "print_few_distractors(vec, Xt, attn_hat, sampled_output, distractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradients**\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = model.gradient_mem(Xt)\n",
    "process_grads(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grads(Xt, attn_hat, grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Permutation**\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = model.permute_attn(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutations(perms, Xt, yt_hat, attn_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adversary**\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_outputs = model.adversarial(Xt, _type='uniform')\n",
    "ad_y, ad_attn = adversarial_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jds = plot_adversarial(Xt, yt_hat, attn_hat, adversarial_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(np.where(np.logical_and(np.array(jds) > 0.5, yt_hat > 0.7))[0])[:30]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 734\n",
    "print_adversarial_example(vec.map2words(X[n]), attn_hat[n], ad_attn[n])\n",
    "print(yt_hat[n], ad_y[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy Runs**\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_runs = model.copy_H_run(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_outputs, copy_attn, copy_H_diff = copy_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_diff(Xt, attn_hat, copy_attn, \"Attention vs Copy Attention\")\n",
    "plot_y_diff(X, attn_hat, yt_hat, copy_outputs)\n",
    "plot_attn_diff(Xt, attn_hat, copy_H_diff, \"Attention vs H difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero Runs**\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_runs = model.zero_H_run(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_outputs, zero_H_diff = zero_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_diff(Xt, attn_hat, zero_H_diff)\n",
    "plot_y_diff(X, attn_hat, yt_hat, zero_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove and Run**\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outputs = model.remove_and_run(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_y_diff(Xt, attn_hat, yt_hat, remove_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perturbation**\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_outputs = model.perturbation_embedding(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pertub_embedding(Xt, attn_hat, yt_hat, perturb_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
