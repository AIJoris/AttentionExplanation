{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.set_printoptions(suppress=True)\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'preprocess/')\n",
    "import vectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pickle.load(open('preprocess/Tweets/vec_adr.p', 'rb'))\n",
    "add_frequencies(vec, vec.seq_text['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.Attn_Word_Pert as M\n",
    "Model = M.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xt = vec.seq_text['train'], vec.seq_text['test']\n",
    "y, yt = vec.label['train'], vec.label['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = filterbylength(X, y, min_length=5, max_length=100)\n",
    "Xt, yt = filterbylength(Xt, yt, min_length=5, max_length=100)\n",
    "\n",
    "Xt, yt = sortbylength(Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = 1 #len(y)/sum(y) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "def train(name='') :\n",
    "    model = Model(vec.vocab_size, vec.word_dim, 64, dirname='tweet', hidden_size=128, pre_embed=vec.embeddings)\n",
    "    best_f1 = 0.0\n",
    "    for i in tqdm_notebook(range(5)) :\n",
    "        loss = model.train(X, y)\n",
    "        o, he = model.evaluate(Xt)\n",
    "        o = np.array(o)\n",
    "        rep = classification_report(yt, (o > 0.5))\n",
    "        f1 = f1_score(yt, (o > 0.5), pos_label=1)\n",
    "        print(rep)\n",
    "        stmt = '%s, %s' % (i, loss)\n",
    "        if True : #f1 > best_f1 :\n",
    "            best_f1 = f1\n",
    "            dirname = model.save_values(add_name=name, save_model=True)\n",
    "            print(\"Model Saved\", f1)\n",
    "        else :\n",
    "            dirname = model.save_values(add_name=name, save_model=False)\n",
    "            print(\"Model not saved\", f1)\n",
    "        f = open(dirname + '/epoch.txt', 'a')\n",
    "        f.write(stmt + '\\n')\n",
    "        f.write(rep + '\\n')\n",
    "        f.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(name='TEST_tweet_adr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dirname) :\n",
    "    model = Model(vec.vocab_size, vec.word_dim, 64, dirname='tweet', hidden_size=128, pre_embed=vec.embeddings)\n",
    "    model.dirname = dirname\n",
    "    model.load_values(dirname)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('outputs/attn_word_tweet/MonOct1516:04:022018_TEST_tweet_adr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_hat, attn_hat = evaluate_and_print(model, Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_entropy(Xt, attn_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 900\n",
    "print_attn(vec.map2words(Xt[n]), attn_hat[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Sampling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vec = vec\n",
    "sampled_output = model.sampling_top(Xt, sample_vocab=100, topnum=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sampled_output, open(model.dirname + '/sampled.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_output = pickle.load(open(model.dirname + '/sampled.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_medians_from_sampling_top(sampled_output, attn_hat, yt_hat, dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distractors = get_distractors(sampled_output, attn_hat)\n",
    "print_few_distractors(vec, Xt, attn_hat, sampled_output, distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_attn(vec.map2words(Xt[1000]), attn_hat[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradients**\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = model.gradient_mem(Xt)\n",
    "process_grads(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grads(Xt, attn_hat, grads, dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Permutation**\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = model.permute_attn(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_permutations(perms, Xt, yt_hat, attn_hat, dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adversarial Attention**\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_outputs = model.adversarial(Xt, _type='uniform')\n",
    "ad_y, ad_attn = adversarial_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jds = plot_adversarial(Xt, yt_hat, attn_hat, adversarial_outputs, dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(np.where(np.logical_and(np.array(jds) > 0.5, yt_hat > 0.7))[0])[:30]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 113\n",
    "print_adversarial_example(vec.map2words(X[n]), attn_hat[n], ad_attn[n])\n",
    "print(yt_hat[n], ad_y[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero Runs** -- p(y|x, c) - p(y|x)\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_runs = model.zero_H_run(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_outputs, zero_H_diff = zero_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_diff(Xt, attn_hat, zero_H_diff, xlabel='Attention', ylabel=\"H(x|c) - H(x)\", \n",
    "               title=\"Attention vs change in hidden state\", save_name=\"hxc-hx.pdf\", dirname=model.dirname)\n",
    "plot_y_diff(X, attn_hat, yt_hat, zero_outputs, xlabel=\"Attention\", ylabel=\"p(y|x, c) - p(y|x)\", \n",
    "            title=\"Attention vs change in output\", save_name=\"pyxc-pyx.pdf\", dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove and Run** -- p(y|x, c) - p(y|c)\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outputs = model.remove_and_run(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_y_diff(Xt, attn_hat, yt_hat, remove_outputs, xlabel=\"Attention\", ylabel=\"p(y|x, c) - p(y|c)\", \n",
    "            title=\"Attention vs change in output\", save_name=\"pyxc-pyc.pdf\", dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perturbation**\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_outputs = model.perturbation_embedding(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pertub_embedding(Xt, attn_hat, yt_hat, perturb_outputs, dirname=model.dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
