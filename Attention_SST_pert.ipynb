{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'preprocess/')\n",
    "import vectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pickle.load(open('preprocess/SST/sst.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.Attn_Word_Pert as AttnModel\n",
    "Model = AttnModel.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = vec.vocab_size\n",
    "embed_size = vec.word_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xt = vec.seq_text['train'], vec.seq_text['test']\n",
    "y, yt = vec.label['train'], vec.label['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 = [i for i, x in enumerate(X) if len(x) <= 2]\n",
    "X = [x for i, x in enumerate(X) if i not in ind_1]\n",
    "y = [x for i, x in enumerate(y) if i not in ind_1]\n",
    "print(len(ind_1))\n",
    "ind_1 = [i for i, x in enumerate(Xt) if len(x) <= 2]\n",
    "Xt = [x for i, x in enumerate(Xt) if i not in ind_1]\n",
    "yt = [x for i, x in enumerate(yt) if i not in ind_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name='') :\n",
    "    model = Model(vocab_size, embed_size, 32, dirname='sst', hidden_size=128)\n",
    "    for i in tqdm_notebook(range(10)) :\n",
    "        loss = model.train(X, y)\n",
    "        print(loss)\n",
    "        o, he = model.evaluate(Xt)\n",
    "        o = np.array(o)\n",
    "        rep = classification_report(yt, (o > 0.5))\n",
    "        print(rep)\n",
    "        stmt = '%s, %s' % (i, loss)\n",
    "        dirname = model.save_values(add_name=name)\n",
    "        f = open(dirname + '/epoch.txt', 'a')\n",
    "        f.write(stmt + '\\n')\n",
    "        f.write(rep + '\\n')\n",
    "        f.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil \n",
    "# shutil.rmtree('outputs/attn_sim_pert_sst', ignore_errors=True)\n",
    "# for i in tqdm_notebook(range(20)) :\n",
    "#     model = train(name='experiments_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dirname) :\n",
    "    model = Model(vocab_size, embed_size, 100, dirname='sst', hidden_size=128)\n",
    "    model.dirname = dirname\n",
    "    model.load_values(dirname)\n",
    "    model.encoder.gen_cells()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exps = os.listdir('outputs/attn_sim_pert_sst/')[:5]\n",
    "exps = [e for e in exps if 'experiments' in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal_list = {}\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for e in exps :\n",
    "    dirname_normal = 'outputs/attn_sim_pert_sst/'+ e\n",
    "    model = load_model(dirname_normal)\n",
    "    o, he = model.evaluate(Xt)\n",
    "    o = np.array(o)\n",
    "    rep = accuracy_score(yt, (o > 0.5))\n",
    "    print(rep)\n",
    "    if rep > 0.7 :\n",
    "        model_normal_list[e] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = list(model_normal_list.keys())\n",
    "exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Xt\n",
    "ytest = yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation -- Pertubation\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pertubations(model) :\n",
    "    if os.path.exists(model.dirname + '/save_pertubations.p') :\n",
    "        print(model.dirname)\n",
    "#         try :\n",
    "#             d = pickle.load(open(model.dirname + '/save_pertubations.p', 'rb'))\n",
    "#             return\n",
    "#         except :\n",
    "#             pass\n",
    "        \n",
    "    model.vec = vec\n",
    "    predict_y, attn_test = model.evaluate(Xtest)\n",
    "    perts_predict, perts_attn, words_sampled = model.sampling(Xtest)\n",
    "        \n",
    "#     model.attn = attn_test\n",
    "    model.perts_predict = perts_predict\n",
    "    model.perts_attn = perts_attn\n",
    "    model.words_sampled = words_sampled\n",
    "    \n",
    "    pickle.dump({'perts_predict' : model.perts_predict, \n",
    "                 'perts_attn' : model.perts_attn,\n",
    "                 'words_sampled' : model.words_sampled }, \n",
    "                open(model.dirname + '/save_pertubations.p', 'wb'))\n",
    "    \n",
    "    model.perts_attn = None\n",
    "    model.perts_predict = None\n",
    "    model.words_sampled = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pertubations(model) :\n",
    "    if os.path.exists(model.dirname + '/save_pertubations.p') :\n",
    "        print(model.dirname)\n",
    "        model.vec = vec\n",
    "        predict_y, attn_test = model.evaluate(Xtest)\n",
    "        try :\n",
    "            d = pickle.load(open(model.dirname + '/save_pertubations.p', 'rb'))\n",
    "        except :\n",
    "            print(\"Error\")\n",
    "            #save_pertubations(model)\n",
    "            #load_pertubations(model)\n",
    "            return\n",
    "        model.attn = attn_test\n",
    "        model.perts_predict = d['perts_predict']\n",
    "        model.perts_attn = d['perts_attn']\n",
    "        model.words_sampled = d['words_sampled']\n",
    "    else :\n",
    "        raise(\"Error : No Pertubations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_median_pertubation(model) :\n",
    "    model.medians = []\n",
    "    model.attn_list = []\n",
    "    for i in range(len(model.perts_attn)) :\n",
    "        attn = model.perts_attn[i]\n",
    "        attn1 = np.diagonal(attn, 0, 0, 2)\n",
    "        attn1 = attn1[:, :len(Xtest[i])]\n",
    "        med = np.median(attn1, 0)\n",
    "        model.medians.append(med)\n",
    "        model.attn_list.append(model.attn[i][:len(Xtest[i])])\n",
    "    model.words_sampled = None\n",
    "    model.perts_attn = None\n",
    "    model.perts_predict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e, model in tqdm_notebook(list(model_normal_list.items())):\n",
    "#     save_pertubations(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(list(model_normal_list.items())):\n",
    "    load_pertubations(model)\n",
    "    save_median_pertubation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    if hasattr(model_normal_list[e], \"perts_predict\") :\n",
    "        highidxs = []\n",
    "        for i in range(len(model_normal_list[e].perts_predict)) :\n",
    "            attn = model_normal_list[e].perts_predict[i][:len(Xtest[i])]\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "            actual = model_normal_list[e].attn[i][:len(Xtest[i])]\n",
    "            \n",
    "            attn1 = np.hstack([actual[:, None], attn[:, :50]])\n",
    "            axes.matshow(attn1, cmap='PuRd', vmin=0, vmax=1)\n",
    "            input_sentence = [vec.idx2word[x] for x in Xtest[i]]\n",
    "            axes.set_yticks(np.arange(len(input_sentence)))\n",
    "\n",
    "            axes.set_yticklabels(input_sentence, fontdict={'fontweight':10})\n",
    "        \n",
    "        plt.show()\n",
    "        print(\"================================\")\n",
    "#         ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    medians = []\n",
    "    if hasattr(model_normal_list[e], \"perts_attn\") :\n",
    "        highidxs = []\n",
    "        for i in range(len(model_normal_list[e].perts_attn)) :\n",
    "            attn = model_normal_list[e].perts_attn[i]\n",
    "            attn1 = np.diagonal(attn, 0, 0, 2)\n",
    "            attn1 = attn1[:, :len(Xtest[i])]\n",
    "            med = np.median(attn1, 0)\n",
    "            medians += list(med)\n",
    "#             if (med > 0.5).any() :\n",
    "#             highidxs.append(i)\n",
    "#             actual = model_normal_list[e].attn[i][:len(Xtest[i])]\n",
    "        \n",
    "#             attn1 = np.vstack([actual, attn1[:50]])\n",
    "#             fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "#             axes.matshow(attn1.T, cmap='PuRd', vmin=0, vmax=1)\n",
    "#             input_sentence = [vec.idx2word[x] for x in Xtest[i]]\n",
    "#             axes.set_yticks(np.arange(len(input_sentence)))\n",
    "\n",
    "#             axes.set_yticklabels(input_sentence, fontdict={'fontweight':10})\n",
    "            \n",
    "#             words = [vec.idx2word[x] for x in model_normal_list[e].words_sampled[i]]\n",
    "#             axes.set_xticks(np.arange(len(words[:50]) + 1))\n",
    "#             axes.set_xticklabels(['actual'] + words[:50], rotation=85)\n",
    "        sns.kdeplot(medians, cumulative=True)\n",
    "        \n",
    "        plt.show()\n",
    "        print(\"================================\")\n",
    "#         ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    if hasattr(model_normal_list[e], \"medians\") :\n",
    "        medians = np.array([x for y in model.medians for x in y])\n",
    "        attn = np.array([x for y in model.attn_list for x in y])\n",
    "        assert len(medians) == len(attn)\n",
    "#         sns.kdeplot(medians, cumulative=True)\n",
    "\n",
    "        filt = np.logical_and(medians > 0.5, attn > 0.5)\n",
    "        print(np.sum(filt)/np.sum(attn > 0.5)*100)\n",
    "#         plt.show()\n",
    "        g = sns.regplot(attn, medians)\n",
    "        g.figure.set_size_inches(16.5, 9.5)\n",
    "        plt.show()\n",
    "        print('='*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation -- Gradient\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gradients(model) :\n",
    "    model.vec = vec\n",
    "    predict_y, attn_test = model.evaluate(Xtest)\n",
    "    grad_test = model.gradient(Xtest)\n",
    "    diff_test = model.zero_H_run(Xtest)\n",
    "    \n",
    "    idxs = {}\n",
    "    for k in grad_test :\n",
    "        idxs[k] = []\n",
    "        for i in range(len(grad_test[k])) :\n",
    "            grad_test[k][i] = np.sum(np.abs(grad_test[k][i]), axis=1) # * sims_test[i]) \n",
    "            if np.sum(grad_test[k][i]) != 0 :\n",
    "                idxs[k].append(i)\n",
    "            else : \n",
    "                print(i)\n",
    "            grad_test[k][i] = grad_test[k][i] / np.sum(grad_test[k][i])\n",
    "        \n",
    "    if hasattr(model, 'attn') :\n",
    "        assert len(model.attn) == len(attn_test)\n",
    "        for i in range(len(attn_test)) :\n",
    "            assert (attn_test[i] == model.attn[i]).all()\n",
    "            \n",
    "    else : model.attn = attn_test\n",
    "        \n",
    "    model.gradients_output = grad_test\n",
    "    model.zero_diff = diff_test\n",
    "    model.idxs = idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    save_gradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def showAttention(fig, ax, input_sentence, model, n):\n",
    "    attn = model.attn[n][:len(Xtest[n])]\n",
    "    grads = [model.gradients_output[k][n][:len(Xtest[n])] for k in model.gradients_output]\n",
    "    grads += [model.zero_diff[k][n][:len(Xtest[n])] for k in model.zero_diff]\n",
    "    grads += [model.medians[n]]\n",
    "    grads += list(model.copy_gradients['diff'][n][1:len(Xtest[n]), :len(Xtest[n])])\n",
    "    attentions = np.stack([attn] + grads, axis=0)\n",
    "    \n",
    "    a1 = attentions\n",
    "    img = ax.imshow(a1, cmap='PuRd', vmin=0, vmax=1, interpolation='none')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"10%\", pad=0.05)\n",
    "    fig.colorbar(img, cax=cax, ax=ax)\n",
    "    \n",
    "    # Set up axes\n",
    "    ax.set_xticks(np.arange(len(input_sentence)))\n",
    "    ax.set_xticklabels(input_sentence, rotation=85)\n",
    "    \n",
    "    ax.set_yticks(np.arange(len(model.gradients_output)+len(model.zero_diff)+1+len(input_sentence)))\n",
    "    ax.set_yticklabels(['attention'] + list(model.gradients_output.keys()) + list(model.zero_diff.keys()) + ['median'] + input_sentence[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    n = 30\n",
    "    meds = np.array([max(x) for x in model.medians])\n",
    "    lens = np.array([len(x) for x in model.medians])\n",
    "    meds[lens < 5] = -100\n",
    "    n = np.argmax(meds)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10,50))\n",
    "    showAttention(fig, axes, [vec.idx2word[x] for x in Xtest[n]], model, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation -- Hidden\n",
    "===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_copies(model) :\n",
    "    model.vec = vec\n",
    "    predict_y, attn_test = model.evaluate(Xtest)\n",
    "    grad_test = model.copy_H_run(Xtest)\n",
    "        \n",
    "    if hasattr(model, 'attn') :\n",
    "        assert len(model.attn) == len(attn_test)\n",
    "        for i in range(len(attn_test)) :\n",
    "            assert (attn_test[i] == model.attn[i]).all()\n",
    "            \n",
    "    else : model.attn = attn_test\n",
    "        \n",
    "    model.copy_gradients = grad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    save_copies(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, model in tqdm_notebook(model_normal_list.items()):\n",
    "    xp, yp = [], []\n",
    "    for i in range(len(testidx)) :\n",
    "        attn = model.attn[i][:len(Xtest[i])]\n",
    "        new_attn = np.diagonal(model.gradients_output['diff'][i])[:len(Xtest[i])]\n",
    "        m = np.argmax(attn)\n",
    "        if len(Xtest[i]) > 4 :\n",
    "            xp.append(attn[m])\n",
    "            yp.append(new_attn[m])\n",
    "            if attn[m] > 0.6 and new_attn[m] > 0.6 :\n",
    "                fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,25))\n",
    "                attn = model.attn[i][:len(Xtest[i])][None, :]\n",
    "                diff = model.gradients_output['diff'][i][:len(Xtest[i]), :len(Xtest[i])]\n",
    "                ax.matshow(np.vstack([diff, attn]), cmap='PuRd', vmin=0, vmax=1)\n",
    "                input_sentence = [vec.idx2word[x] for x in Xtest[i]]\n",
    "                ax.set_xticks(np.arange(len(input_sentence)))\n",
    "                ax.set_xticklabels(input_sentence, rotation=85)\n",
    "                \n",
    "                ax.set_yticks(np.arange(len(input_sentence)+1))\n",
    "                ax.set_yticklabels(input_sentence+['actual'])\n",
    "                plt.show()\n",
    "                \n",
    "    plt.scatter(xp, yp, s=5)\n",
    "    plt.show()\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
