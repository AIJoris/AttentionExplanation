{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('../caml-mimic/mimicdata/mimic3/notes_labeled.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "def reformat(code, is_diag):\n",
    "    code = ''.join(code.split('.'))\n",
    "    if is_diag:\n",
    "        if code.startswith('E'):\n",
    "            if len(code) > 4:\n",
    "                code = code[:4] + '.' + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                code = code[:3] + '.' + code[3:]\n",
    "    else:\n",
    "        code = code[:2] + '.' + code[2:]\n",
    "    return code\n",
    "\n",
    "def load_code_descriptions(version='mimic3'):\n",
    "    desc_dict = defaultdict(str)\n",
    "    DATA_DIR = '../caml-mimic/mimicdata'\n",
    "    with open(\"%s/D_ICD_DIAGNOSES.csv\" % (DATA_DIR), 'r') as descfile:\n",
    "        r = csv.reader(descfile)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            code = row[1]\n",
    "            desc = row[-1]\n",
    "            desc_dict[reformat(code, True)] = desc\n",
    "            \n",
    "    with open(\"%s/D_ICD_PROCEDURES.csv\" % (DATA_DIR), 'r') as descfile:\n",
    "        r = csv.reader(descfile)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            code = row[1]\n",
    "            desc = row[-1]\n",
    "            if code not in desc_dict.keys():\n",
    "                desc_dict[reformat(code, False)] = desc\n",
    "                \n",
    "    with open('%s/ICD9_descriptions' % DATA_DIR, 'r') as labelfile:\n",
    "        for i,row in enumerate(labelfile):\n",
    "            row = row.rstrip().split()\n",
    "            code = row[0]\n",
    "            if code not in desc_dict.keys():\n",
    "                desc_dict[code] = ' '.join(row[1:])\n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict = load_code_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285.0 Sideroblastic anemia\n",
      "285.1 Acute posthemorrhagic anemia\n",
      "285.21 Anemia in chronic kidney disease\n",
      "285.22 Anemia in neoplastic disease\n",
      "285.29 Anemia of other chronic disease\n",
      "285.3 Antineoplastic chemotherapy induced anemia\n",
      "285.8 Other specified anemias\n",
      "285.9 Anemia, unspecified\n",
      "285 Other and unspecified anemias\n",
      "285.2 Anemia of chronic disease\n"
     ]
    }
   ],
   "source": [
    "for k in desc_dict :\n",
    "    if '285' in k : print(k, desc_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_label(x, positive_icd9) :\n",
    "    return any([positive_icd9 in y for y in x.split(';')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['has_c1'] = codes['LABELS'].apply(lambda x : has_label(x, '285.1'))\n",
    "codes['has_c2'] = codes['LABELS'].apply(lambda x : has_label(x, '285.2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_c1  has_c2\n",
       "False   False     45661\n",
       "        True       2562\n",
       "True    False      4283\n",
       "        True        216\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.groupby(['has_c1', 'has_c2']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_pos_label = codes[codes['has_pos'] == True]\n",
    "data_for_neg_label = codes[codes['has_pos'] == False].sample(len(data_for_pos_label), random_state=14829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_for_neg_label, data_for_pos_label]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def cleaner(text, spacy=True) :\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    if spacy :\n",
    "        text = [t.text.lower() for t in nlp(text)]\n",
    "    else :\n",
    "        text = [t.lower() for t in text.split()]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r'\\[\\s*\\*\\s*\\*(.*?)\\*\\s*\\*\\s*\\]', ' <DE> ', text)\n",
    "    text = re.sub(r'([^a-zA-Z0-9])(\\s*\\1\\s*)+', r'\\1 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = ['qqq' if any(char.isdigit() for char in word) else word for word in text.split(' ')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(data['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869e41355ada4beea01f601dc548de1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6694), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(texts)), miniters=100) :\n",
    "    texts[i] = cleaner(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in desc_dict :\n",
    "    desc_dict[k] = cleaner(desc_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del codes\n",
    "data['TEXT'] = texts\n",
    "data.to_csv('/media/sarthak/data/projects/Transparency/preprocess/MIMIC/cleaned_data' + positive_icd9 + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorizer as v\n",
    "Vectorizer = v.Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vectorizer(min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(list(data['TEXT']) + list(desc_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.label2idx = {k:i for i, k in enumerate(desc_dict.keys())}\n",
    "vec.idx2label = {i:k for k, i in vec.label2idx.items()}\n",
    "vec.label2desc = desc_dict\n",
    "vec.code_desc = {k:vec.convert_to_sequence([x])[0] for k, x in desc_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "idxs = {}\n",
    "idxs['train'], idxs['test'] = train_test_split(data.index, stratify=data['has_pos'], test_size=0.2, random_state=12939)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['train', 'test']\n",
    "import numpy as np\n",
    "vec.seq_text = {}\n",
    "vec.label = {}\n",
    "for k in keys :\n",
    "    filtered = data[data.index.isin(idxs[k])]\n",
    "    vec.seq_text[k] = vec.texts_to_sequences(list(data['TEXT']))\n",
    "    vec.label[k] = np.where(list(data['has_pos']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[vec.idx2word[x] for x in y] for k in vec.seq_text for y in vec.seq_text[k]]\n",
    "sentences += [[vec.idx2word[x] for x in y] for y in vec.code_desc.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, size=200, window=10, min_count=1, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192620926, 286996240)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18937 words in model out of 18938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.21415395,  0.17256159,  0.22251911, ..., -1.00560653,\n",
       "        -0.65924704, -1.60224962],\n",
       "       [ 0.96354502,  5.50281048, -0.25558323, ...,  2.81642532,\n",
       "         2.47439027,  2.4510026 ],\n",
       "       ...,\n",
       "       [ 4.68103075, -0.09528357,  0.07303315, ..., -0.73452204,\n",
       "        -2.78040624, -1.82796764],\n",
       "       [ 2.63897204,  0.53498065, -0.54808551, ..., -4.52820301,\n",
       "        -8.33251095, -2.8496809 ],\n",
       "       [ 0.97723985, -0.05751874,  0.95762306, ..., -2.89463377,\n",
       "        -3.56042004, -1.29545152]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.extract_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vec, open('MIMIC/vec_icd9_' + positive_icd9 + '.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
