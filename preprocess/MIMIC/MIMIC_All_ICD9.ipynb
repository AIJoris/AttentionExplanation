{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('MIMIC/cleaned_data_full.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['train', 'dev', 'test']\n",
    "hadm_ids = {x:list(pd.read_csv('../caml-mimic/mimicdata/mimic3/%s_50_hadm_ids.csv'%x, header=None)[0]) for x in keys}\n",
    "hadm_ids_total = hadm_ids['train'] + hadm_ids['dev'] + hadm_ids['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_codes = list(pd.read_csv('../caml-mimic/mimicdata/mimic3/TOP_50_CODES.csv', header=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "def reformat(code, is_diag):\n",
    "    code = ''.join(code.split('.'))\n",
    "    if is_diag:\n",
    "        if code.startswith('E'):\n",
    "            if len(code) > 4:\n",
    "                code = code[:4] + '.' + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                code = code[:3] + '.' + code[3:]\n",
    "    else:\n",
    "        code = code[:2] + '.' + code[2:]\n",
    "    return code\n",
    "\n",
    "def load_code_descriptions(version='mimic3'):\n",
    "    desc_dict = defaultdict(str)\n",
    "    DATA_DIR = '../caml-mimic/mimicdata'\n",
    "    with open(\"%s/D_ICD_DIAGNOSES.csv\" % (DATA_DIR), 'r') as descfile:\n",
    "        r = csv.reader(descfile)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            code = row[1]\n",
    "            desc = row[-1]\n",
    "            desc_dict[reformat(code, True)] = desc\n",
    "            \n",
    "    with open(\"%s/D_ICD_PROCEDURES.csv\" % (DATA_DIR), 'r') as descfile:\n",
    "        r = csv.reader(descfile)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            code = row[1]\n",
    "            desc = row[-1]\n",
    "            if code not in desc_dict.keys():\n",
    "                desc_dict[reformat(code, False)] = desc\n",
    "                \n",
    "    with open('%s/ICD9_descriptions' % DATA_DIR, 'r') as labelfile:\n",
    "        for i,row in enumerate(labelfile):\n",
    "            row = row.rstrip().split()\n",
    "            code = row[0]\n",
    "            if code not in desc_dict.keys():\n",
    "                desc_dict[code] = ' '.join(row[1:])\n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict = load_code_descriptions()\n",
    "desc_dict = {k:v for k, v in desc_dict.items() if k in top_50_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = codes[codes['HADM_ID'].isin(hadm_ids_total)].reset_index().drop(['index'], axis=1)\n",
    "assert len(codes) == len(hadm_ids_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['LABELS'] = codes['LABELS'].apply(lambda x : \";\".join(list(set(x.split(';')) & set(top_50_codes))))\n",
    "labels = list(codes['LABELS'])\n",
    "\n",
    "assert all([len(x.strip().split(';')) > 0  for x in labels])\n",
    "\n",
    "def is_valid_code_set(x) :\n",
    "    l = x.split(';')\n",
    "    return len(set(l) - set(top_50_codes)) == 0\n",
    "\n",
    "assert all([is_valid_code_set(x) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def cleaner(text, spacy=True) :\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    if spacy :\n",
    "        text = [t.text.lower() for t in nlp(text)]\n",
    "    else :\n",
    "        text = [t.lower() for t in text.split()]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r'\\[\\s*\\*\\s*\\*(.*?)\\*\\s*\\*\\s*\\]', ' <DE> ', text)\n",
    "    text = re.sub(r'([^a-zA-Z0-9])(\\s*\\1\\s*)+', r'\\1 ', text)\n",
    "#     text = re.sub(r'(\\W)', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = ['qqq' if any(char.isdigit() for char in word) else word for word in text.split(' ')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in desc_dict :\n",
    "    desc_dict[k] = cleaner(desc_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorizer as v\n",
    "Vectorizer = v.Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vectorizer(min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(list(codes['TEXT']) + list(desc_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.label2idx = {k:i for i, k in enumerate(desc_dict.keys())}\n",
    "vec.idx2label = {i:k for k, i in vec.label2idx.items()}\n",
    "vec.label2desc = desc_dict\n",
    "vec.code_desc = {k:vec.convert_to_sequence([x])[0] for k, x in desc_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.seqs = {}\n",
    "vec.labels = {}\n",
    "for k in keys :\n",
    "    code_filtered = codes[codes['HADM_ID'].isin(hadm_ids[k])]\n",
    "    vec.seqs[k] = vec.texts_to_sequences(list(code_filtered['TEXT']))\n",
    "    labels = list(code_filtered['LABELS'])\n",
    "    labels = [x.split(';') for x in labels]\n",
    "    vec.labels[k] = [[vec.label2idx[y] for y in x] for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vec.label_one_hot = {}\n",
    "for k in keys :\n",
    "    vec.label_one_hot[k] = np.zeros((len(vec.seqs[k]), max(vec.idx2label.keys())+1))\n",
    "    for i, x in enumerate(vec.labels[k]) :\n",
    "        vec.label_one_hot[k][i, x] = 1\n",
    "        \n",
    "for k in keys :\n",
    "    for i, x in enumerate(vec.labels[k]) :\n",
    "        assert (set(np.where(vec.label_one_hot[k][i] == 1)[0]) == set(vec.labels[k][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load('MIMIC/mimic_embedding_model.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22312 words in model out of 22316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 6.07958188e-01,  7.56901864e-01, -4.58418838e-01, ...,\n",
       "         3.27159178e-01,  1.05838462e+00, -1.00027972e+00],\n",
       "       [ 3.20409388e-01, -9.84535349e-01, -1.66852078e+00, ...,\n",
       "        -1.20682319e-01,  2.20697478e+00, -1.14211235e+00],\n",
       "       ...,\n",
       "       [ 1.16788733e+00, -9.24137831e-01,  1.75671399e+00, ...,\n",
       "         9.75742284e-03, -2.87074357e-01, -2.45802402e-01],\n",
       "       [ 9.31499293e-04, -9.84110713e-01, -1.11939907e+00, ...,\n",
       "        -6.90321016e+00,  3.93742228e+00, -1.51261103e+00],\n",
       "       [-7.20303178e-01, -1.40906677e-01, -2.27291822e+00, ...,\n",
       "        -1.95523810e+00,  7.60727704e-01, -1.39611304e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.extract_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vec, open('MIMIC/vec_icd9.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
