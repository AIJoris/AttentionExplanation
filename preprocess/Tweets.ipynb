{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import *\n",
    "data = pd.read_csv('Tweets/training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tok = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleaner(text) :\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    toks = tok.tokenize(text)\n",
    "    toks = [t.lower() for t in toks]\n",
    "    text = ['qqq' if any(char.isdigit() for char in word) else word for word in toks]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = list(data[5])\n",
    "target = [0 if x == 0 else 1 for x in list(data[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [cleaner(s) for s in strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_idx, test_idx = train_test_split(range(len(strings)), test_size = 0.01, stratify=target, random_state=13020)\n",
    "target_train = [target[i] for i in train_idx]\n",
    "train_idx, rem_idx = train_test_split(train_idx, test_size=0.9, stratify=target_train, random_state=12930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158400, 16000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx), len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [strings[i] for i in train_idx]\n",
    "X_test = [strings[i] for i in test_idx]\n",
    "\n",
    "y_train = [target[i] for i in train_idx]\n",
    "y_test = [target[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorizer\n",
    "vec = vectorizer.Vectorizer(min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(X_train + X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.seq_text = {}\n",
    "vec.seq_text['train'] = vec.get_seq_for_docs(X_train)\n",
    "vec.seq_text['test'] = vec.get_seq_for_docs(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.label = { 'train' : y_train, 'test' : y_test } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors, GloVe, CharNGram, FastText\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "vectors = Vectors('wiki.simple.vec', url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.word_dim = vectors.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vec.embeddings = np.zeros((len(vec.idx2word), vec.word_dim))\n",
    "for i, word in vec.idx2word.items() :\n",
    "    vec.embeddings[i] = vectors[word].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vec, open('Tweets/vec.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
