{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('../caml-mimic/mimicdata/mimic3/notes_labeled.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['train', 'dev', 'test']\n",
    "hadm_ids = {x:list(pd.read_csv('../caml-mimic/mimicdata/mimic3/%s_50_hadm_ids.csv'%x, header=None)[0]) for x in keys}\n",
    "hadm_ids_total = hadm_ids['train'] + hadm_ids['dev'] + hadm_ids['test']\n",
    "\n",
    "top_50_codes = list(pd.read_csv('../caml-mimic/mimicdata/mimic3/TOP_50_CODES.csv', header=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "def reformat(code, is_diag):\n",
    "    code = ''.join(code.split('.'))\n",
    "    if is_diag:\n",
    "        if code.startswith('E'):\n",
    "            if len(code) > 4:\n",
    "                code = code[:4] + '.' + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                code = code[:3] + '.' + code[3:]\n",
    "    else:\n",
    "        code = code[:2] + '.' + code[2:]\n",
    "    return code\n",
    "\n",
    "def load_code_descriptions(version='mimic3'):\n",
    "    desc_dict = defaultdict(str)\n",
    "    DATA_DIR = '../caml-mimic/mimicdata'\n",
    "    with open(\"%s/D_ICD_DIAGNOSES.csv\" % (DATA_DIR), 'r') as descfile:\n",
    "        r = csv.reader(descfile)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            code = row[1]\n",
    "            desc = row[-1]\n",
    "            desc_dict[reformat(code, True)] = desc\n",
    "            \n",
    "    with open(\"%s/D_ICD_PROCEDURES.csv\" % (DATA_DIR), 'r') as descfile:\n",
    "        r = csv.reader(descfile)\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            code = row[1]\n",
    "            desc = row[-1]\n",
    "            if code not in desc_dict.keys():\n",
    "                desc_dict[reformat(code, False)] = desc\n",
    "                \n",
    "    with open('%s/ICD9_descriptions' % DATA_DIR, 'r') as labelfile:\n",
    "        for i,row in enumerate(labelfile):\n",
    "            row = row.rstrip().split()\n",
    "            code = row[0]\n",
    "            if code not in desc_dict.keys():\n",
    "                desc_dict[code] = ' '.join(row[1:])\n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict = load_code_descriptions()\n",
    "desc_dict = {k:v for k, v in desc_dict.items() if k in top_50_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = codes[codes['HADM_ID'].isin(hadm_ids_total)].reset_index().drop(['index'], axis=1)\n",
    "assert len(codes) == len(hadm_ids_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['LABELS'] = codes['LABELS'].apply(lambda x : \";\".join(list(set(x.split(';')) & set(top_50_codes))))\n",
    "labels = list(codes['LABELS'])\n",
    "\n",
    "assert all([len(x.strip().split(';')) > 0  for x in labels])\n",
    "\n",
    "def is_valid_code_set(x) :\n",
    "    l = x.split(';')\n",
    "    return len(set(l) - set(top_50_codes)) == 0\n",
    "\n",
    "assert all([is_valid_code_set(x) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def cleaner(text, spacy=True) :\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    if spacy :\n",
    "        text = [t.text.lower() for t in nlp(text)]\n",
    "    else :\n",
    "        text = [t.lower() for t in text.split()]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r'\\[\\s*\\*\\s*\\*(.*?)\\*\\s*\\*\\s*\\]', ' <DE> ', text)\n",
    "    text = re.sub(r'([^a-zA-Z0-9])(\\s*\\1\\s*)+', r'\\1 ', text)\n",
    "#     text = re.sub(r'(\\W)', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = ['qqq' if any(char.isdigit() for char in word) else word for word in text.split(' ')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(codes['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669cd59665384189a32b595ec7642b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(texts)), miniters=100) :\n",
    "    texts[i] = cleaner(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in desc_dict :\n",
    "    desc_dict[k] = cleaner(desc_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['TEXT'] = texts\n",
    "codes.to_csv('/media/sarthak/data/projects/Transparency/preprocess/MIMIC/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorizer as v\n",
    "Vectorizer = v.Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vectorizer(min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(list(codes['TEXT']) + list(desc_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.label2idx = {k:i for i, k in enumerate(desc_dict.keys())}\n",
    "vec.idx2label = {i:k for k, i in vec.label2idx.items()}\n",
    "vec.label2desc = desc_dict\n",
    "vec.code_desc = {k:vec.convert_to_sequence([x])[0] for k, x in desc_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.seqs = {}\n",
    "vec.labels = {}\n",
    "for k in keys :\n",
    "    code_filtered = codes[codes['HADM_ID'].isin(hadm_ids[k])]\n",
    "    vec.seqs[k] = vec.texts_to_sequences(list(code_filtered['TEXT']))\n",
    "    labels = list(code_filtered['LABELS'])\n",
    "    labels = [x.split(';') for x in labels]\n",
    "    vec.labels[k] = [[vec.label2idx[y] for y in x] for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vec.label_one_hot = {}\n",
    "for k in keys :\n",
    "    vec.label_one_hot[k] = np.zeros((len(vec.seqs[k]), max(vec.idx2label.keys())+1))\n",
    "    for i, x in enumerate(vec.labels[k]) :\n",
    "        vec.label_one_hot[k][i, x] = 1\n",
    "        \n",
    "for k in keys :\n",
    "    for i, x in enumerate(vec.labels[k]) :\n",
    "        assert (set(np.where(vec.label_one_hot[k][i] == 1)[0]) == set(vec.labels[k][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[vec.idx2word[x] for x in y] for k in vec.seqs for y in vec.seqs[k]]\n",
    "sentences += [[vec.idx2word[x] for x in y] for y in vec.code_desc.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, size=200, window=10, min_count=1, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160234038, 238430380)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22315 words in model out of 22316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.33724129, -0.72580487,  0.25685626, ...,  0.84722298,\n",
       "        -0.42704654,  0.16344222],\n",
       "       [ 1.36212325, -3.3724916 ,  1.49810886, ..., -4.18783808,\n",
       "         3.35530281, -0.17716061],\n",
       "       ...,\n",
       "       [ 0.39726099,  0.06424714,  0.01182108, ...,  0.05343216,\n",
       "         0.01368389, -0.1997826 ],\n",
       "       [ 3.05400419, -0.07490952,  4.42545509, ...,  3.40820122,\n",
       "        -1.88489342, -1.60525978],\n",
       "       [ 0.53760332, -1.25615954,  0.02455853, ...,  0.53178424,\n",
       "        -1.84809422, -0.37117359]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.extract_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vec, open('MIMIC/vec_icd9.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
