{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('MIMIC/readmissions_readmit.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def cleaner(text, spacy=True) :\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    if spacy :\n",
    "        text = [t.text.lower() for t in nlp(text)]\n",
    "    else :\n",
    "        text = [t.lower() for t in text.split()]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r'\\[\\s*\\*\\s*\\*(.*?)\\*\\s*\\*\\s*\\]', ' DEIDENTIFY ', text)\n",
    "    text = re.sub(r'([^a-zA-Z0-9])(\\s*\\1\\s*)+', r'\\1 ', text)\n",
    "    text = re.sub(r'(\\W)', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = ['qqq' if any(char.isdigit() for char in word) else word for word in text.split(' ')]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(codes['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0432536f7dcc4f14a0bec70c2167643e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8411), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(texts)), miniters=100) :\n",
    "    texts[i] = cleaner(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['text'] = texts\n",
    "codes.to_csv('MIMIC/cleaned_readmit_only_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorizer as v\n",
    "Vectorizer = v.Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vectorizer(min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.fit(list(codes['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "keys = {}\n",
    "keys['train'], keys['test'] = train_test_split(list(codes['hadm_id']), stratify=list(codes['readmission_30']), test_size = 0.1, random_state=1034)\n",
    "# keys['train'], keys['dev'] = train_test_split(keys['train'], test_size=0.1, random_state=1035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.seqs = {}\n",
    "vec.labels = {}\n",
    "for k in keys :\n",
    "    code_filtered = codes[codes['hadm_id'].isin(keys[k])]\n",
    "    vec.seqs[k] = vec.texts_to_sequences(list(code_filtered['text']))\n",
    "    vec.labels[k] = list(code_filtered['readmission_30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[vec.idx2word[x] for x in y] for k in vec.seqs for y in vec.seqs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, size=200, window=10, min_count=1, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129461018, 201966080)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18685 words in model out of 18686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.06836064,  0.20034975,  0.56518489, ...,  0.31307557,\n",
       "        -1.59697318, -1.1097424 ],\n",
       "       [-6.25817823, -4.71902704, 10.04657364, ..., -7.18311071,\n",
       "         0.85669881, -1.98961699],\n",
       "       ...,\n",
       "       [-0.24864443, -1.03268707,  0.57694995, ...,  1.15038824,\n",
       "        -0.97294104,  0.32838869],\n",
       "       [-0.28442943,  0.44261733, -2.66807628, ...,  0.7622484 ,\n",
       "        -3.90297222,  1.01426923],\n",
       "       [-1.2994324 ,  0.57265449,  0.35146809, ..., -0.7985571 ,\n",
       "         1.21987605,  1.99669313]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.extract_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vec, open('MIMIC/vec_admit_only.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
